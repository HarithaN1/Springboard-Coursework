# Springboard Data Science Mini-Projects

Welcome! This repository contains my data science mini-projects, ranging from data wrangling and statistical inference to machine learning and data visualization.


### Machine Learning

**[Linear Regression with Boston Housing Dataset](https://github.com/andrewjsiu/Springboard-Coursework/blob/master/Machine_Learning_Exercises/linear_regression/Mini_Project_Linear_Regression.ipynb):** I use `scikit-learn` library to build a linear regression model to predict the housing prices in Boston. The various features include per capita crime rate, average number of rooms per dwelling, and pupil-teacher ratio by town. I also split the data into training and testing sets in order to measure how well the model built with the training set can predict the 'unseen' data in the test set. I show how multiple rounds of cross-validation performed on different partitions help limit the problem of overfitting a particular training subset and thus reduce variability of the model.

**[Classification and Logistic Regression](https://github.com/andrewjsiu/Springboard-Coursework/blob/master/Machine_Learning_Exercises/logistic_regression/Mini_Project_Logistic_Regression.ipynb):** I use cross-validation and grid search to find the best regularization parameter **C** for the logistic regression. Regularization applies a penalty for increasing the coefficient estimates in order to reduce overfitting. The regularization parameter **C** in `scikit-learn` is the inverse of the shrinkage parameter lambda. Larger lambda or smaller **C** increases the shrinkage pentalty and shrinks the coefficient estimates toward zero. By default scikit-learn sets **C=1** in logistic regression, so some amount of regularization is used even if **C** is not specified. Regularization is good at reducing the variance of the predictions but increasing the bias at the same time. `GridSearchCV` performs a cross-validated grid-search over a parameter grid. We need to specify an estimation method, parameter values for the estimator and a scoring method. The results show the best estimator, the score of the best estimator, and the parameter setting that yields the best score.

**[Text Classification with Naive Bayes](https://github.com/andrewjsiu/Springboard-Coursework/blob/master/Machine_Learning_Exercises/naive_bayes/Mini_Project_Naive_Bayes.ipynb):** I analyze the movie reviews from the rotten tomatoes database. The goal is to train a classifier to predict whether a critic's movie review is 'fresh' or 'rotten.' To preprocess the text, `sklearn.feature_extraction.text.CountVectorizer` allows us convert the collection of movie reviews into a matrix of token counts. The parameter `min_df` is used to removed terms that are too rare, and `max_df` is used to remove terms that are too common. I then train a multinomial Naive Bayes classifier assuming that features are conditionally independent given the class. In Naive Bayes, alpha is an additive (Laplace/Lidstone) smoothing parameter. A larger alpha will reduce the variance of the model (and overfitting) but increase bias at the same time. We can think of alpha as a pseudocount of the number of times a word has been seen. In the following code, I use grid search to find the best alpha as well as the best `min_df` that will maximize the probability of observing the training data.

For feature selection, we can create an identity matrix with the size of the number of features/words, each row representing exactly one feature/word. We then use this one word to predict the probabilitiy of freshness or rottenness of a review that contains this word. If one single word can generate high probability of a review being fresh or rotten, that implies this feature has a high predictive power. Reviews containing words such as perfect, touching and masterpiece tend to be fresh, while words like unfortunately, dull and worst tend to predict rotten reviews.

I also improve the model by using features that are n-grams instead of words,  Naive Bayes model where the features are either unigram or bigrams in order to capture multiword phrases. Term Frequency and Inverse Document Frequency (TF-IDF):  
Counting the term frequency in a document is a rough measure of term importance. But if a frequent term appears in almost every document, it is then not very useful in prediction. So we can multiple this term frequency with the inverse of its popularity in all documents. This will downweight words like "movie" that shows up in all reviews and increase the weight of words that appear only in a few documents.

The best Random Forest classifier builds 90 decision trees and is trained with features/words that appear in at least 0.1% of all reivews. The training accuracy is close to 100%, but the testing accuracy is only about 69%. Even the best Random Forest classifier still misclassifies a review describing a 'not remarkable' movie as fresh.

### Advance Machine Learning Topics


### Data Wrangling

**[JSON Exercises](https://github.com/andrewjsiu/Springboard-Coursework/blob/master/Data_Wrangling/data_wrangling_json/json_exercise.ipynb):** The dataset on the World Bank projects is available in a JSON file. I first load the data as a Pandas dataframe and find that China, Indonesia and Vietnam have the most projects with the World Bank. Then I load the JSON file as a string, normalize the project themes, and find that environment and natural resources management, rural development and human development are the project themes with the highest frequencies. 

**[XML Exercises](https://github.com/andrewjsiu/Springboard-Coursework/blob/master/Data_Wrangling/data_wrangling_xml/xml_exercise.ipynb):** The Mondial database contains geographical terrains and various physical features in the world. I use `xml.etree.ElementTree` module to parse the data, which are stored as elements in a hierarchical structure. Each element has a tag, a number of attributes, a text string, and a number of child elements. I find that (1) Monaco, Japan and Bermuda have the lowest infant morality rate; (2) Shanghai, Istanbul and Mumbai have the largest city population; (3) Han Chinese, Europeans and Indo-Aryan are ethnic groups with the largest overall population, and (4) the longest river in the world is Amazonas, the largest lake is Caspian Sea, and the airport at the highest elevation is El Alto International. 

### Exploratory Data Analysis

**[Human Body Temperature](https://github.com/andrewjsiu/Springboard-Coursework/blob/master/Exploratory_Data_Analysis/data_human_temperature/inferential_statistics_exercise_1_human_temperatures.ipynb):** 
I analyze a dataset of human body temperatures and test whether the true average temperature is 98.6 degrees F. As women have a higher average temperature than men, I also test whether there is such gender difference in temperature.   

